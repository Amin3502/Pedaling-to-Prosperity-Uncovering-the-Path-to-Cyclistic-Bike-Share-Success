---
title: "Pedaling to Prosperity: Uncovering the Path to Cyclistic Bike-Share Success"
author: "Amin Hassanzadeh"
date: "2023-05-01"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Revolutionizing Urban Mobility: A Year-Long Analysis of Cyclistic Bike-Share

###   In this comprehensive analysis, we delve into the intricacies of Cyclistic Bike-Share's remarkable journey to success. Drawing inspiration from Kevin Hartman's insightful case study, 'Sophisticated, Clear, and Polishedâ€™: Divvy and Data Visualization,' our mission is to consolidate the extensive Divvy dataset into a cohesive framework. Our objective is to provide a meticulous examination, shedding light on the pivotal question: "In what ways do members and casual riders utilize Cyclistic bikes differently?" Through rigorous data analysis and visualization, we aim to uncover the underlying patterns and factors contributing to Cyclistic's ascent in the bike-share industry.

# ----------

## We install required packages:
## tidyverse for data import and wrangling,
## lubridate for date functions,
## ggplot for visualization

# -----------

```{r}
library(tidyverse)  #helps wrangle data
library(lubridate)  #helps wrangle date attributes
library(ggplot2)  #helps visualize data
getwd() #displays your working directory

```

# ----------

# Part 1: Data Collection and Preparation

# ----------

### In this initial phase, we focus on gathering the essential data required for our analysis. We ensure that the data is complete, relevant, and in a format suitable for our research. This stage forms the foundation for all subsequent steps. Therefore we upload Divvy datasets (csv files):

```{r}
df04_2022 <- read_csv("202204-divvy-tripdata.csv")
df05_2022 <- read_csv("202205-divvy-tripdata.csv")
df06_2022 <- read_csv("202206-divvy-tripdata.csv")
df07_2022 <- read_csv("202207-divvy-tripdata.csv")
df08_2022 <- read_csv("202208-divvy-tripdata.csv")
df09_2022 <- read_csv("202209-divvy-tripdata.csv")
df10_2022 <- read_csv("202210-divvy-tripdata.csv")
df11_2022 <- read_csv("202211-divvy-tripdata.csv")
df12_2022 <- read_csv("202212-divvy-tripdata.csv")
df01_2023 <- read_csv("202301-divvy-tripdata.csv")
df02_2023 <- read_csv("202302-divvy-tripdata.csv")
df03_2023 <- read_csv("202303-divvy-tripdata.csv")
```

# -----------

# Part 2: Data Wrangling and Consolidation

# ----------

### During this step, we merge and harmonize the collected data into a single, unified dataset. By doing so, we create a consolidated source that simplifies the subsequent analytical processes.
### For this reason, we compare column names each of the files.
### While the names don't have to be in the same order, they DO need to match perfectly before we can use a command to join them into one file.

```{r}
colnames(df04_2022)
colnames(df05_2022)
colnames(df06_2022)
colnames(df07_2022)
colnames(df08_2022)
colnames(df09_2022)
colnames(df10_2022)
colnames(df11_2022)
colnames(df12_2022)
colnames(df01_2023)
colnames(df02_2023)
colnames(df03_2023)
```

### We inspect the dataframes and look for incongruencies:

```{r}
str(df04_2022)
str(df05_2022)
str(df06_2022)
str(df07_2022)
str(df08_2022)
str(df09_2022)
str(df10_2022)
str(df11_2022)
str(df12_2022)
str(df01_2023)
str(df02_2023)
str(df03_2023)
```

### We stack individual month's data frames into one big data frame:

```{r}
all_trips <- bind_rows(df04_2022, df05_2022, df06_2022, df07_2022, df08_2022, df09_2022, df10_2022, df11_2022, df12_2022, df01_2023, df02_2023, df03_2023)
```

### We remove lat, and long fields as this data was dropped beginning in 2022:

```{r}
all_trips <- all_trips %>%  
  select(-c(start_lat, start_lng, end_lat, end_lng))
```

# -----------

# Part 3: Data Cleaning and Enhancement for Analysis
# ----------

### In Step 3, we meticulously clean and refine the dataset, addressing inconsistencies, missing values, and any imperfections. This prepares the data for in-depth analysis and ensures the accuracy and reliability of our findings. We inspect the new table that has been created:

```{r}
colnames(all_trips)  #List of column names
nrow(all_trips)  #How many rows are in data frame?
dim(all_trips)  #Dimensions of the data frame?
head(all_trips)  #See the first 6 rows of data frame.  Also tail(all_trips)
str(all_trips)  #See list of columns and data types (numeric, character, etc)
summary(all_trips)  #Statistical summary of data. Mainly for numerics
table(all_trips$member_casual) # Checking the levels of factors
table(all_trips$rideable_type) # Checking the levels of factors
```

## In this phase, we identify and address critical data issues to ensure the integrity and readiness of our dataset for further analysis. The specific challenges we address include:

### (1) Data Aggregation Granularity: We recognize that our data is initially only aggregated at the ride-level, which may prove overly granular for our analytical goals. To enhance the data's utility, we introduce supplementary columns such as date, month, and year. This enhancement expands our capacity to perform aggregated analyses at different temporal levels, thereby deepening our insights.

### (2) Calculating Ride Length: In response to the absence of the "tripduration" column in the 2020Q1 data, we introduce a calculated field, "ride_length," to ensure consistency across the entire dataset. This calculated field provides a unified measure for the length of each ride, which is essential for our subsequent analytical processes.

### (3) Handling Anomalies: We identify instances of negative values in the "tripduration" column, stemming from rides where Divvy temporarily withdrew bikes from circulation for Quality Control purposes. In order to maintain data accuracy and relevance, we exclude these anomalous rides from our dataset.


```{r}
all_trips$date <- as.Date(all_trips$started_at) #The default format is yyyy-mm-dd
all_trips$year <- format(as.Date(all_trips$date), "%Y")
all_trips$month <- format(as.Date(all_trips$date), "%m")
all_trips$day <- format(as.Date(all_trips$date), "%d")
all_trips$day_of_week <- ordered(format(as.Date(all_trips$date), "%A"))
```

### To ensure consistency and precision in our analysis, we incorporate a "ride_length" calculation for the entire dataset, expressed in seconds. We employ the principles outlined in the R documentation on time intervals, which can be found at https://stat.ethz.ch/R-manual/R-devel/library/base/html/difftime.html. This calculation enables us to derive accurate ride durations, a crucial metric for our analytical processes.


```{r}
all_trips$ride_length <- difftime(all_trips$ended_at,all_trips$started_at)
```

### Conduct a thorough examination of the column structures to gain insight into the dataset's organization and content.

```{r}
str(all_trips)
table(all_trips$year)
table(all_trips$month)
table(all_trips$day)
table(all_trips$day_of_week)
is.numeric(all_trips$ride_length)
```

### Transform the "ride_length" variable from a categorical factor into a numeric format, allowing us to perform data calculations and analyses effectively.

```{r}
all_trips$ride_length <- as.numeric(as.character(all_trips$ride_length))
is.numeric(all_trips$ride_length)
```

## In the pursuit of data integrity, we identify and exclude specific entries characterized by anomalous attributes, including instances where bikes were temporarily withdrawn from docks for quality checks or where "ride_length" exhibited negative values. To maintain data quality and consistency, we are creating an updated version of the dataframe, denoted as "v2." Detailed information on the removal process can be found at https://www.datasciencemadesimple.com/delete-or-drop-rows-in-r-with-conditions-2/.


```{r}
all_trips_v2 <- drop_na(all_trips[!(all_trips$start_station_name == "HQ QR" | all_trips$ride_length<0),])
```

# -----------

# Part 4: Descriptive Data Analysis

# -----------

###In this critical phase, we dive into the dataset, utilizing descriptive statistical techniques to gain a comprehensive understanding of the data's characteristics. We extract initial insights and patterns that will guide our subsequent analysis. We descriptive analysis on ride_length (all figures in seconds):

```{r}
mean(all_trips_v2$ride_length) #straight average (total ride length / rides)
median(all_trips_v2$ride_length) #midpoint number in the ascending array of ride lengths
max(all_trips_v2$ride_length) #longest ride
min(all_trips_v2$ride_length) #shortest ride
```



### We conduct a comparative analysis between members and casual users to discern key differences and patterns in their interactions with the Cyclistic Bike-Share service.

```{r}
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual, FUN = mean)
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual, FUN = median)
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual, FUN = max)
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual, FUN = min)
```

### We examine the daily average ride duration, differentiating between members and casual users, to reveal insights into their respective usage patterns.

```{r}
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual + all_trips_v2$day_of_week, FUN = mean)
```

### We perform a detailed analysis of ridership data, stratified by user type and weekdays, to unveil comprehensive patterns and trends within the dataset.

```{r}
all_trips_v2 %>% 
  mutate(weekday = wday(started_at, label = TRUE)) %>%  #creates weekday field using wday()
  group_by(member_casual, weekday) %>%  #groups by usertype and weekday
  summarise(number_of_rides = n()							#calculates the number of rides and average duration 
  ,average_duration = mean(ride_length)) %>% 		# calculates the average duration
  arrange(member_casual, weekday)								# sorts
```

### We generate visual representations to illustrate the distribution of rides based on rider types, facilitating a clearer understanding of the dataset.

```{r}
all_trips_v2 %>% 
  mutate(weekday = wday(started_at, label = TRUE)) %>% 
  group_by(member_casual, weekday) %>% 
  summarise(number_of_rides = n()
            ,average_duration = mean(ride_length)) %>% 
  arrange(member_casual, weekday)  %>% 
  ggplot(aes(x = weekday, y = number_of_rides, fill = member_casual)) +
  geom_col(position = "dodge")
```

### We produce a visualization to portray the average ride durations, providing a visual means to comprehend the data distribution.

```{r}
all_trips_v2 %>% 
  mutate(weekday = wday(started_at, label = TRUE)) %>% 
  group_by(member_casual, weekday) %>% 
  summarise(number_of_rides = n()
            ,average_duration = mean(ride_length)) %>% 
  arrange(member_casual, weekday)  %>% 
  ggplot(aes(x = weekday, y = average_duration, fill = member_casual)) +
  geom_col(position = "dodge")
```

# ----------

# Part 5: Summary File Export for Further Analysis

# ----------

### The final step of Part 1 involves exporting a summary file that encapsulates the essential data and insights obtained from the descriptive analysis. This summary file serves as the foundation for deeper explorations and advanced analytics in the upcoming phases of our project. We create a csv file that we will visualize in Excel, Tableau, or other softwares:

```{r}
counts <- aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual + all_trips_v2$day_of_week, FUN = mean)
write.csv(counts, file = 'D:/Data Analysis/Project/Case Study 1/Divvy_Project/avg_ride_length.csv')
```


































